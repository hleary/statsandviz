---
title: "R Tutorial: Hotspot Analysis using Getis Ord Gi"
author: "Heatherlee Leary"
date: "2023-04-27"
output: 
  html_document:
    toc: yes
    theme: cerulean
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "C:/Users/hlear/Desktop/statsandviz/advanced_topic")

```


&ensp;

## **Introduction**

#### This tutorial will walk you through the steps and R code to perform a hotspot analysis using the Getis Ord Gi method.    

**Note:** Getis Ord Gi and Gi* are the same thing.  

&ensp;

### **Example Scenario**

As an example, we will look at tree equity score data for the city of Tucson, Arizona, USA. A tree equity score (TES) is "a metric that helps cities assess how well they are delivering equitable tree canopy cover to all residents. It is derived from tree canopy cover, climate, demographic and socioeconomic data" [(American Forests 2023)](https://www.treeequityscore.org/methodology/). TES values range from 0 - 100, with a lower score indicating lower equity.  

Imagine we want to assess spatial patterns of TES across Tucson. Specifically, we want to know whether there are statistically significant clusters of high and low TES values. This information can help the City of Tucson prioritize where resources are allocated for tree planting initiatives and other climate mitigation strategies.  

&ensp;

### **Spatial Autocorrelation**

#### Before moving on, it's important to understand the concept of spatial autocorrelation.

*Spatial autocorrelation* is a measure of how a set of spatial features or their associated values are related to each other in space. It describes the extent to which nearby features or values are similar (clustered) or dissimilar (dispersed).     

Spatial Autocorrelation can be positive or negative. Positive spatial autocorrelation indicates that features or values are clustered in space, and nearby locations tend to have similar values or characteristics. Negative spatial autocorrelation indicates that features or values are dispersed in space, and nearby locations tend to have dissimilar values or characteristics.  

Spatial autocorrelation can be evaluated at a global or local level. Global spatial autocorrelation provides an overall assessment of the spatial pattern across the entire study area, while a local indicator of spatial association (LISA) identifies hotspots and coldspots of high or low values for each feature, offering a more detailed analysis of spatial patterns.

&ensp;

A free eBook on Geospatial Analysis: [de Smith, M. J., Goodchild, M. F., Longley, P. A. & Associates. (2018). Geospatial Analysis: A Comprehensive Guide to Principles, Techniques and Software Tools (6th ed.)](https://www.spatialanalysisonline.com/HTML/index.html). See the section on [Local Indicators of Spatial Association](https://www.spatialanalysisonline.com/HTML/index.html?local_indicators_of_spatial_as.htm). 



&ensp;

### **R Packages**

You will need the following R packages:  
`sf`      *for simple features*  
`sfdep`   *for spatial analyses*  
`spdep`   *for spatial analyses*  
`dyplyr`  *for data manipulation*  
`tidyr`   *for data manipulation*  
`ggplot2` *for data visualization*  

`r require(sf)        # Simple features    
require(sfdep)     # Spatial analyses  
require(spdep)     # Spatial analyses   
require(dplyr)     # Data manipulation    
require(tidyr)     # Data manipulation    
require(ggplot2)   # Data visualization`


&ensp;

## **Explore Raw Data**

#### As with any analysis, we begin by exploring the raw data.  

I have already cleaned this dataset and *removed NA values*. The original TES dataset can be accessed from the [City of Tucson's open data platform](https://gisdata.tucsonaz.gov/datasets/cotgis::tree-equity-scores-tucson-1/about)  

```{r}
# Read in data
tes_data <- st_read("data/tree_equity_data.shp")

# View first six rows of the dataset
head(tes_data)
```

This is a simple feature data type with 330 rows (Tucson neighborhood polygons), which contains the following columns: 

* NID = unique neighborhood identifier
* nghbrhd = Tucson neighborhood name
* treEqty = tree equity score
* geometry = spatial polygon geometries

&ensp;

Let's visualize the tree equity variable (treEqty):

```{r}
# Visualize tree equity as histogram
hist(tes_data$treEqty, main = "Distribution of Tree Equity Scores", xlab = "Tree Equity Score", ylab = "Frequency")

# Visualize tree equity across neighborhoods
ggplot(tes_data) +
  geom_sf(aes(fill = treEqty), color = "black", lwd = 0.15) +
  scale_fill_gradient(name = "Tree Equity Score",
                      low = "white",
                      high = "darkgreen") +
  ggtitle("Tree Equity Scores of Tucson Neighborhoods") +
  labs(caption = "Data source: City of Tucson") +
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position = "right")
```


&ensp;

## **Check Empty Neighbor Sets**

#### Create a list of neighbors for each polygon in 'tes_data'.  

```{r}
# Create a neighbor list based on queen contiguity
list_nb <- poly2nb(tes_data, queen = TRUE)
```

The `poly2nb()` function creates a list of neighbors for each polygon in 'tes_data'. In this example, the relationship will be based on a queen contiguity criterion (`queen=TRUE`), which considers polygons to be neighbors if they share a boundary or a vertex.  

&ensp;

#### Next, we check for empty neighbor sets (polygons without neighbors).   

If there are empty neighbors, then this will eventually cause an error and prevent the analysis from running.  

There are a few ways to address empty neighbor sets. Here, we can simply remove them. Note that removing empty neighbor sets could impact the results of spatial analyses.  

```{r}
# Check for empty neighbor sets
# card() calculates number of neighbors for each polygon in the list
# which() finds polygons with 0 neighbors
empty_nb <- which(card(list_nb) == 0)
empty_nb       

# Remove polygons with empty neighbor sets from the data
tes_subset <- tes_data[-empty_nb, ]
```



&ensp;

If you need to know the neighborhood names for reporting, then run the following code.  

```{r}
# Subset 'tes_data' to extract polygons with empty neighbor sets
empty_polygons <- tes_data[empty_nb, ]
empty_polygons$nghbrhd  # print neighborhood names
```

&ensp;

## **Global G Test**

#### Test for global spatial autocorrelation

`globalG.test` (or `global_g_test()`) computes a global test for spatial autocorrelation using a Monte Carlo simulation approach (simulated spatial datasets that have the same spatial structure as the original data but are randomly permuted). It tests the null hypothesis of no spatial autocorrelation against the alternative hypothesis of positive spatial autocorrelation.    

```{r}
# Now that we removed empty neighbor sets (tes_subset)
# Identify neighbors with queen contiguity (edge/vertex touching)
tes_nb <- poly2nb(tes_subset, queen = TRUE)

# Binary weighting assigns a weight of 1 to all neighboring features 
# and a weight of 0 to all other features
tes_w_binary <- nb2listw(tes_nb, style="B")

# Calculate spatial lag of TreEqty
tes_lag <- lag.listw(tes_w_binary, tes_subset$treEqty)
```

I used binary weighting to assess the overall spatial distribution. Binary weighting assigns a weight of 1 to all neighboring features (ignoring relative size or extent) and a weight of 0 to all other features. More about this can be learned from ESRI's article ["How High/Low Clustering (Getis-Ord General G) works"](https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/h-how-high-low-clustering-getis-ord-general-g-spat.htm#:~:text=High%2FLow%20Clustering%20will%20only%20work%20with%20positive%20values.,binary%20weighting%20scheme%20is%20recommended%20for%20this%20statistic.) and ["Spatial Weights"](https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/spatial-weights.htm#:~:text=Variable%20weights%20fall%20into%20a%20range%20from%200,where%20features%20have%20an%20unequal%20number%20of%20neighbors.), though there are many resources available.  

&ensp;

```{r}
# Test for global G statistic of TreEqty
globalG.test(tes_subset$treEqty, tes_w_binary)
```

**Global G Test Interpretation**

The output shows a standard deviate of 2.419, which indicates that the observed clustering of tree equity is 2.419 standard deviations away from what would be expected under the null hypothesis of no clustering. This value is associated with a p-value of 0.007783, so observed clustering is statistically significant at the 0.05 level. The alternative hypothesis is "greater," which means that the analysis is looking for clusters of high tree equity values.  

The sample estimates of the Global G statistic, Expectation, and Variance are also reported. The Global G statistic is 1.567748e-02, which is the observed value of the clustering statistic for the entire dataset. The Expectation is 1.536557e-02, which is the expected value of the clustering statistic under the null hypothesis of no clustering. Finally, the Variance is 1.662723e-08, which is an estimate of the variance of the clustering statistic under the null hypothesis.  

Overall, the output suggests that there is statistically significant clustering of high tree equity values.  

&ensp;

## **Local Gi Test**

#### Test for local spatial autocorrelation (hotspots)  

```{r}
# Identify neighbors, create weights, calculate spatial lag
tes_nbs <- tes_subset |> 
  mutate(
    nb = st_contiguity(geometry),        # neighbors share border/vertex
    wt = st_weights(nb),                 # row-standardized weights
    tes_lag = st_lag(treEqty, nb, wt)    # calculate spatial lag of TreEqty
  ) 

```

&ensp;

We can calculate the Gi statistic using `local_g_perm()`. The Gi is the ratio of the spatial lag of a feature to the sum of the feature's values for its neighbors. A positive Gi value indicates that a feature and its neighbors have high values, while a negative Gi value indicates that they have low values. The magnitude of the Gi value indicates the strength of the clustering.  

```{r}
# Calculate the Gi using local_g_perm
tes_hot_spots <- tes_nbs |> 
  mutate(
    Gi = local_g_perm(treEqty, nb, wt, nsim = 999)
    # nsim = number of Monte Carlo simulations (999 is default)
  ) |> 
  # The new 'Gi' column itself contains a dataframe 
  # We can't work with that, so we need to 'unnest' it
  unnest(Gi) 
```


&ensp;

Let's do a cursory visualization of Gi values across Tucson.  

```{r}
# Cursory visualization
# Plot looks at gi values for all locations
tes_hot_spots |> 
  ggplot((aes(fill = gi))) +
  geom_sf(color = "black", lwd = 0.15) +
  scale_fill_gradient2() # makes the value 0 (random) be the middle

```

We're getting an idea of spatial patterns of TES values for Tucson neighborhoods. But is it statistically significant? We will consider p-values in the next step.  

&ensp;

Almost done!  

```{r}
# Create a new data frame called 'tes_hot_spots"
tes_hot_spots |> 
  # with the columns 'gi' and 'p_folded_sim"
  # 'p_folded_sim' is the p-value of a folded permutation test
  select(gi, p_folded_sim) |> 
  mutate(
    # Add a new column called "classification"
    classification = case_when(
      # Classify based on the following criteria:
      gi > 0 & p_folded_sim <= 0.01 ~ "Very hot",
      gi > 0 & p_folded_sim <= 0.05 ~ "Hot",
      gi > 0 & p_folded_sim <= 0.1 ~ "Somewhat hot",
      gi < 0 & p_folded_sim <= 0.01 ~ "Very cold",
      gi < 0 & p_folded_sim <= 0.05 ~ "Cold",
      gi < 0 & p_folded_sim <= 0.1 ~ "Somewhat cold",
      TRUE ~ "Insignificant"
    ),
    # Convert 'classification' into a factor for easier plotting
    classification = factor(
      classification,
      levels = c("Very hot", "Hot", "Somewhat hot",
                 "Insignificant",
                 "Somewhat cold", "Cold", "Very cold")
    )
  ) |> 
  # Visualize the results with ggplot2
  ggplot(aes(fill = classification)) +
  geom_sf(color = "black", lwd = 0.1) +
  scale_fill_brewer(type = "div", palette = 5) +
  theme_void() +
  labs(
    fill = "Hot Spot Classification",
    title = "Tree Equity Hot Spots in Tucson"
  )

```

&ensp;

**Hotspot Analysis Interpretation**

The hotspot analysis map assessing tree equity across Tucson reveals a clear pattern of spatial clustering, with hotspots in northern neighborhoods and coldspots in southern neighborhoods.


&ensp;
&ensp;

---

## **Disclaimer and Acknowledgements**

**Disclaimer**  
This tutorial was created by a non-expert for educational purposes only. While efforts have been made to ensure the accuracy of the information provided, users should verify any information before applying it to their own analysis. The author accepts no responsibility or liability for any errors or omissions, or for any damage or loss arising from the use of this tutorial.  

**Acknowledgements**  
Tree equity data was obtained from the [City of Tucson's open data platform](https://gisdata.tucsonaz.gov/datasets/cotgis::tree-equity-scores-tucson-1/about). The code used in this tutorial is adapted and modified from Josiah Parry's YouTube tutorial ["Hotspot Analysis in R: GIS Fundamentals"](https://www.youtube.com/watch?v=OnMNZwJywjs&t=360s), accessible from his [GitHub](https://github.com/JosiahParry/youtube-tutorials/tree/main/hot-spot-analysis).

&ensp;
&ensp;

---

## **Session Info**

```{r}
sessionInfo()
```






